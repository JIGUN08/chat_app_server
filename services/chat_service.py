#chat_service.py
import json
import os
import base64
from django.utils import timezone
from typing import Optional, Dict, Any, Tuple
from openai import OpenAI, APIError, AsyncOpenAI
from django.core.files.uploadedfile import UploadedFile

from api.models import ChatMessage, UserAttribute, UserActivity, ActivityAnalytics, UserRelationship
from .context_service import get_activity_recommendation, search_activities_for_context
from .memory_service import extract_and_save_user_context_data
from .image_captioning_service import ImageCaptioningService
from . import vector_service, location_service, schedule_service, emotion_service, prompt_service, emoticon_service
from datetime import date # date ì¶”ê°€


def process_chat_interaction(request, user_message_text: str, latitude: Optional[float] = None, longitude: Optional[float] = None, image_file: Optional[UploadedFile] = None):
    """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ìœ¨í•©ë‹ˆë‹¤."""
    user = request.user
    bot_message_text = "ì£„ì†¡í•©ë‹ˆë‹¤. API ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    explanation = ""
    bot_message_obj = None
    user_message_obj = None

    try:
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        client = OpenAI()

        # 0ë‹¨ê³„: ì´ëª¨í‹°ì½˜ íŒŒì‹±
        user_message_for_llm = emoticon_service.parse_emoticon(user_message_text)

        # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ (ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°)
        image_analysis_context = None
        image_b64_data = None
        if image_file:
            print("--- [ë””ë²„ê·¸] ì´ë¯¸ì§€ íŒŒì¼ ê°ì§€ë¨. 1ì°¨ ë¶„ì„ ì‹œì‘ ---")
            
            # ì¶”ê°€ëœ ë””ë²„ê¹… ë¡œê·¸
            print(f"--- [ë””ë²„ê·¸] íŒŒì¼ëª…: {image_file.name}, Content-Type: {image_file.content_type} ---")

            # ImageCaptioningServiceê°€ Base64ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, íŒŒì¼ ë‚´ìš©ì„ ì¸ì½”ë”©í•˜ì—¬ ì „ë‹¬
            image_b64_data = base64.b64encode(image_file.read()).decode('utf-8')
            image_file.seek(0) # íŒŒì¼ì„ ë‹¤ì‹œ ì½ì„ ìˆ˜ ìˆë„ë¡ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦¼

            analyzer = ImageCaptioningService()
            # ì—…ë¡œë“œëœ íŒŒì¼ì˜ content_typeì„ í•¨ê»˜ ì „ë‹¬
            analysis_result = analyzer.analyze_image(image_b64_data, user_message_text, image_file.content_type)
            if analysis_result:
                image_analysis_context = analysis_result
                print("--- [ë””ë²„ê·¸] 1ì°¨ ë¶„ì„ ì™„ë£Œ --- ")
            else:
                print("--- [ê²½ê³ ] 1ì°¨ ë¶„ì„ ì‹¤íŒ¨ --- ")

        # 2ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        history = ChatMessage.objects.filter(user=user).order_by('-timestamp')
        time_contexts = _get_time_contexts(history)
        # ë²¡í„° ê²€ìƒ‰ì€ ì´ë¯¸ì§€ê°€ ì—†ì„ ë•Œë§Œ ìˆ˜í–‰í•˜ì—¬ íš¨ìœ¨ì„± ì¦ëŒ€
        assembled_contexts = _assemble_context_data(user, user_message_for_llm, latitude, longitude, bool(image_file))
        
        # 3ë‹¨ê³„: ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ í¬í•¨)
        final_system_prompt = prompt_service.build_final_system_prompt(user, time_contexts, assembled_contexts, image_analysis_context)
        messages = _prepare_llm_messages(final_system_prompt, history, user_message_for_llm)
        

        # 4ë‹¨ê³„: ìµœì¢… LLM í˜¸ì¶œ (íŒŒì¸íŠœë‹ëœ ëª¨ë¸)
        model_to_use = os.getenv("FINETUNED_MODEL_ID", "gpt-4.1")
        response_json = _call_openai_api(client, model_to_use, messages)
        
        # 5ë‹¨ê³„: ì‘ë‹µ ì²˜ë¦¬ ë° ì €ì¥
        bot_message_text, explanation, bot_message_obj, user_message_obj = _finalize_chat_interaction(
            request, user_message_text, response_json, history, api_key, image_file
        )

    except APIError as e:
        print(f"OpenAI API ìš”ì²­ ì‹¤íŒ¨: {e}")
        bot_message_text = f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    except (KeyError, IndexError, json.JSONDecodeError) as e:
        print(f"API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {e}")
        bot_message_text = "API ì‘ë‹µ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤."
    except Exception as e:
        import traceback
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        bot_message_text = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    # user_message_objë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
    return bot_message_text, explanation, bot_message_obj, user_message_obj

def _get_time_contexts(history):
    """í˜„ì¬ ì‹œê°„ ë° ë§ˆì§€ë§‰ ëŒ€í™”ì™€ì˜ ì‹œê°„ ê°„ê²©ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    now_utc = timezone.now()
    korea_tz = timezone.get_default_timezone()
    now_korea = now_utc.astimezone(korea_tz)
    
    weekdays = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
    day_of_week = weekdays[now_korea.weekday()]
    time_str = now_korea.strftime(f'%Yë…„ %mì›” %dì¼ {day_of_week} %Hì‹œ %Më¶„')
    current_time_context = f"[ì‹œê°„ ì •ë³´]: í˜„ì¬ ëŒ€í•œë¯¼êµ­ ì‹œê°„ì€ ì •í™•íˆ '{time_str}'ì´ì•¼. ì‹œê°„ê³¼ ê´€ë ¨ëœ ëª¨ë“  ì§ˆë¬¸ì— ì´ ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•´ì„œ ë‹µí•´ì•¼ í•´. ì ˆëŒ€ ë‹¤ë¥¸ ì‹œê°„ì„ ë§í•´ì„œëŠ” ì•ˆ ë¼"
    
    time_awareness_context = ""
    if history.exists():
        last_interaction = history.first()
        time_difference = now_utc - last_interaction.timestamp
        if time_difference.total_seconds() > 3600:
            hours = int(time_difference.total_seconds() // 3600)
            minutes = int((time_difference.total_seconds() % 3600) // 60)
            time_gap_str = f"{hours}ì‹œê°„ {minutes}ë¶„"
            last_message_text = last_interaction.message
            sender = "ë„¤ê°€" if last_interaction.is_user else "ë‚´ê°€"
            time_awareness_context = f"[ìµœê·¼ ë§ˆì§€ë§‰ ëŒ€í™”ì •ë³´]: ë§ˆì§€ë§‰ ëŒ€í™”ë¡œë¶€í„° ì•½ {time_gap_str}ì´ ì§€ë‚¬ì–´. ë§ˆì§€ë§‰ì— {sender} í•œ ë§ì€ '{last_message_text}'ì´ì—ˆì–´. ì´ ì‹œê°„ì˜ ê³µë°±ì„ ë„¤ ìºë¦­í„°ì— ë§ê²Œ ì¬ì¹˜ìˆê²Œ ì–¸ê¸‰í•˜ë©° ëŒ€í™”ë¥¼ ì‹œì‘í•´ì¤˜."

    return current_time_context, time_awareness_context

def _assemble_context_data(user, user_message_text, latitude=None, longitude=None, has_image=False):
    """ì‚¬ìš©ìì˜ ê¸°ì–µê³¼ ê´€ë ¨ëœ ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    contexts = {}
    # 0. ì˜¤ëŠ˜ì˜ ì¼ì • ì»¨í…ìŠ¤íŠ¸
    schedule_context = ""
    try:
        today_schedules = schedule_service.get_schedules_for_day(user, date.today())
        if today_schedules:
            schedule_contents = [s.content.strip() for s in today_schedules if s.content and s.content.strip()]
            if schedule_contents:
                schedule_context = f"[ì‚¬ìš©ìì˜ ì˜¤ëŠ˜ ì¼ì • (ì°¸ê³ ìš©)]: {', '.join(schedule_contents)}"
                contexts['schedule'] = schedule_context
    except Exception as e:
        print(f"--- Could not build schedule context due to an error: {e} ---")


    # 1. ìœ„ì¹˜ ì»¨í…ìŠ¤íŠ¸ ë° ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì²œ ì»¨í…ìŠ¤íŠ¸
    if latitude is not None and longitude is not None:
        location_context = location_service.get_location_context(latitude, longitude)
        if location_context:
            contexts['location'] = location_context
       
            
        location_recommendation_result = location_service.get_location_based_recommendation(user, user_message_text, latitude, longitude)
        if location_recommendation_result:
            contexts['location_recommendation'] = location_recommendation_result

    # 2. ë²¡í„° ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ (ì´ë¯¸ì§€ê°€ ì—†ì„ ë•Œë§Œ ìˆ˜í–‰)
    if not has_image:
        try:
            collection = vector_service.get_or_create_collection()
            similar_results = vector_service.query_similar_messages(collection, user_message_text, user.id, n_results=5)
            if similar_results and isinstance(similar_results, dict) and similar_results.get('documents'):
                past_conversations = [f"{meta.get('speaker', 'ì•Œìˆ˜ì—†ìŒ')}: {doc}" for doc, meta in zip(similar_results['documents'], similar_results['metadatas'])]
                contexts['vector_search'] = "[ê³¼ê±° ìœ ì‚¬í•œ ëŒ€í™” ë‚´ìš©(ë²¡í„°DB)]: " + " | ".join(past_conversations)
        except Exception as e:
            print(f"--- ë²¡í„° ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e} ---")

    # 3. ì‚¬ìš©ì ì†ì„± ì»¨í…ìŠ¤íŠ¸
    user_attributes = UserAttribute.objects.filter(user=user)
    if user_attributes.exists():
        attribute_strings = [f"{attr.fact_type}: {attr.content}" for attr in user_attributes]
        contexts['attributes'] = "[ì‚¬ìš©ì ì†ì„±]: " + ", ".join(attribute_strings)

    # 4. ì‚¬ìš©ì í™œë™ ì»¨í…ìŠ¤íŠ¸
    activity_strings = []
    try:
        recent_activities = UserActivity.objects.filter(user=user).order_by('-activity_date', '-created_at')[:5]
        if recent_activities:
            activity_strings.extend([
                f"{act.activity_date.strftime('%Y-%m-%d') if act.activity_date else 'ë‚ ì§œ ë¯¸ìƒ'} '{act.place}' ë°©ë¬¸" +
                (f" (ë™í–‰: {act.companion})" if act.companion else "") +
                (f" (ë©”ëª¨: {act.memo})" if act.memo else "")
                for act in recent_activities
            ])
    except Exception as e:
        print(f"--- í™œë™ ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e} ---")

    search_context = search_activities_for_context(user, user_message_text)
    if search_context:
        activity_strings.append(search_context)
    
    recommendation_context = get_activity_recommendation(user, user_message_text)
    if recommendation_context:
        activity_strings.append(recommendation_context)

    if activity_strings:
        contexts['activity'] = "[ì‚¬ìš©ì í™œë™]: " + "\n".join(activity_strings)

    # 5. í™œë™ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸
    try:
        recent_analytics = ActivityAnalytics.objects.filter(user=user).order_by('-period_start_date')[:3]
        if recent_analytics.exists():
            analytics_strings = [
                f"'{an.period_start_date.strftime('%Y-%m-%d')}ë¶€í„° {an.period_type} ë™ì•ˆ "
                f"ì¥ì†Œ: {an.place}, ë™í–‰: {an.companion or 'ì—†ìŒ'}, íšŸìˆ˜: {an.count}íšŒ'"
                for an in recent_analytics
            ]
            contexts['analytics'] = "[ì‚¬ìš©ì í™œë™ ë¶„ì„]: " + "\n".join(analytics_strings)
    except Exception as e:
        print(f"--- í™œë™ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e} ---")

    # 6. ì¸ê°„ê´€ê³„ ì»¨í…ìŠ¤íŠ¸
    try:
        user_relationships = UserRelationship.objects.filter(user=user)
        if user_relationships.exists():
            relationship_strings = []
            for rel in user_relationships:
                details = f"{rel.name} ({rel.relationship_type})"
                if rel.position:
                    details += f", í¬ì§€ì…˜: {rel.position}"
                if rel.traits:
                    details += f", íŠ¹ì§•: {rel.traits}"
                relationship_strings.append(details)
            
            relationship_strings = [f"{rel.name} ({rel.relationship_type}, íŠ¹ì§•: {rel.traits})" for rel in user_relationships]
            contexts['relationship'] = "[ì‚¬ìš©ìì˜ ì¸ê°„ê´€ê³„]: " + "\n".join(relationship_strings)
    except Exception as e:
        print(f"--- ì‚¬ìš©ì ê´€ê³„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e} ---")

    # ë””ë²„ê¹…ì„ ìœ„í•´ ëª¨ë“  ìˆ˜ì§‘ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë§ˆì§€ë§‰ì— í•œë²ˆì— ì¶œë ¥
    for key, value in contexts.items():
        print(f"--- [ë””ë²„ê·¸] {key} ì»¨í…ìŠ¤íŠ¸: {value} ---")

    return contexts

def _prepare_llm_messages(final_system_prompt, history, user_message_text):
    """API ìš”ì²­ì„ ìœ„í•œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
    messages = [{'role': 'system', 'content': final_system_prompt}]
    recent_history = history[:10]
    for chat in reversed(recent_history):
        role = "user" if chat.is_user else "assistant"
        messages.append({'role': role, 'content': chat.message})
    messages.append({'role': 'user', 'content': user_message_text})
    return messages

def _call_openai_api(client: OpenAI, model_to_use: str, messages: list, stream_mode: bool = False) -> Dict[str, Any]:
    """OpenAI APIë¥¼ í˜¸ì¶œí•˜ê³  ì‘ë‹µ JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print(f"--- Using Model: {model_to_use}, Stream: {stream_mode} ---")

    params ={
        "model":model_to_use,
        "messages":messages,
        "temperature":0.7,
        "top_p":0.9,
        "frequency_penalty":0.2,
        "presence_penalty":0.1,
        "stream":stream_mode
    }
    
    # ìŠ¤íŠ¸ë¦¬ë°ì´ ì•„ë‹ ë•Œë§Œ JSON ì‘ë‹µ í˜•ì‹ì„ ìš”ì²­í•©ë‹ˆë‹¤.
    if not stream_mode:
        params["response_format"] = {"type": "json_object"}
        
    response = client.chat.completions.create(params)

    # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì¼ ê²½ìš° responseëŠ” Generator ê°ì²´ê°€ ë©ë‹ˆë‹¤.
    if stream_mode:
        return response # Generator ê°ì²´ ë°˜í™˜
    else:
        return response.model_dump() # ì¼ë°˜ ì‘ë‹µì€ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜

def _finalize_chat_interaction(request, user_message_text, response_json, history, api_key, image_file: Optional[UploadedFile] = None):
    """ì„±ê³µì ì¸ LLM ì‘ë‹µì„ ì²˜ë¦¬í•˜ê³  ê´€ë ¨ ë°ì´í„°ë¥¼ RDBì™€ ë²¡í„° DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    user = request.user
    bot_message_text = "ìŒ... ìƒê°ì„ ì •ë¦¬í•˜ëŠ” ë° ì‹œê°„ì´ ì¢€ ê±¸ë¦¬ë„¤. ë‹¤ì‹œ í•œë²ˆ ë§í•´ì¤„ë˜?"
    explanation = "AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ."
    bot_message_obj = None
    user_message_obj = None

    try:
        if 'choices' not in response_json or not response_json['choices'] or \
           'message' not in response_json['choices'][0] or \
           'content' not in response_json['choices'][0]['message']:
            raise ValueError("OpenAI API ì‘ë‹µì— 'content' í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

        content_from_llm_raw = response_json['choices'][0]['message']['content']

        if content_from_llm_raw is None:
            raise ValueError("OpenAI API ì‘ë‹µì˜ 'content' í•„ë“œê°€ Noneì…ë‹ˆë‹¤.")

        # --- ìŠ¤ë§ˆíŠ¸ íŒŒì‹± ë¡œì§ ì‹œì‘ ---
        parsed_successfully = False
        try:
            # ê°€ì¥ ë¨¼ì €, ì „ì²´ê°€ ìœ íš¨í•œ JSONì¸ì§€ ì‹œë„
            content_from_llm = json.loads(content_from_llm_raw)
            if 'answer' in content_from_llm:
                bot_message_text = content_from_llm.get('answer', '').strip()
                explanation = content_from_llm.get('explanation', 'ì„¤ëª… ì—†ìŒ.')
                parsed_successfully = True
            else:
                 explanation = f"LLM ì‘ë‹µ JSONì— 'answer' í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {content_from_llm}"
                 bot_message_text = "AI ì‘ë‹µ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (answer í‚¤ ëˆ„ë½)"

        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ë¬¸ìì—´ ë‚´ì—ì„œ JSONì„ ì°¾ì•„ë³´ëŠ” ë¡œì§
            try:
                start_index = content_from_llm_raw.find('{')
                end_index = content_from_llm_raw.rfind('}') + 1
                if start_index != -1 and end_index != 0:
                    json_str = content_from_llm_raw[start_index:end_index]
                    content_from_llm = json.loads(json_str)
                    if 'answer' in content_from_llm:
                        bot_message_text = content_from_llm.get('answer', '').strip()
                        explanation = content_from_llm.get('explanation', 'ì„¤ëª… ì—†ìŒ.')
                        parsed_successfully = True
                    else:
                        explanation = f"ì¶”ì¶œëœ JSONì— 'answer' í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {content_from_llm}"
                        bot_message_text = "AI ì‘ë‹µ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¶”ì¶œëœ JSONì— answer í‚¤ ëˆ„ë½)"

            except json.JSONDecodeError:
                 explanation = f"LLM ì‘ë‹µì—ì„œ JSONì„ ì¶”ì¶œí•˜ì—¬ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                 bot_message_text = "AI ì‘ë‹µ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (JSON íŒŒì‹± ì‹¤íŒ¨)"
        
        # ìµœì¢…ì ìœ¼ë¡œ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆë‹¤ë©´, ì›ë³¸ í…ìŠ¤íŠ¸ë¼ë„ ë‹µë³€ìœ¼ë¡œ ì‚¬ìš©
        if not parsed_successfully and content_from_llm_raw.strip():
            bot_message_text = content_from_llm_raw.strip()
            explanation = "AIê°€ ì§€ì •ëœ JSON í˜•ì‹ì„ ë”°ë¥´ì§€ ì•Šì•˜ìœ¼ë‚˜, ì›ë³¸ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."
        elif not parsed_successfully: # íŒŒì‹±ì— ì™„ì „íˆ ì‹¤íŒ¨í–ˆê³ , ì›ë³¸ ì‘ë‹µë„ ë¹„ì–´ìˆê±°ë‚˜ ì—†ìŒ
            bot_message_text = f"AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ: '{content_from_llm_raw}'. ì„¤ëª…: {explanation}"
            explanation = "LLM ì‘ë‹µ íŒŒì‹±ì— ì‹¤íŒ¨í•˜ì—¬ ë””ë²„ê·¸ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
        
        # ë‹µë³€ì´ ë¹„ì–´ìˆëŠ” ê²½ìš° ë°©ì§€
        if not bot_message_text.strip():
            bot_message_text = "ìŒ... ë­ë¼ ë‹µí•´ì•¼ í• ì§€ ì˜ ëª¨ë¥´ê² ì–´. ë‹¤ë¥¸ ì§ˆë¬¸ í•´ì¤„ë˜?"
            explanation = "íŒŒì‹± í›„ ìµœì¢… ë‹µë³€ì´ ë¹„ì–´ìˆì–´ ëŒ€ì²´ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."

        # --- ìŠ¤ë§ˆíŠ¸ íŒŒì‹± ë¡œì§ ë ---

    except (ValueError, KeyError, IndexError) as e:
        explanation = f"LLM ì‘ë‹µ êµ¬ì¡° íŒŒì‹± ì‹¤íŒ¨: {e}"
    except Exception as e:
        explanation = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}"

    # ChromaDB ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
    collection = vector_service.get_or_create_collection()

    # ChatMessage ì €ì¥ ì‹œ image_fileì„ ì§ì ‘ ì‚¬ìš©
    user_message_obj = ChatMessage.objects.create(user=user, message=user_message_text, image=image_file, is_user=True)
    vector_service.upsert_message(collection, user_message_obj)

    bot_message_obj = ChatMessage.objects.create(user=user, message=bot_message_text, is_user=False)
    vector_service.upsert_message(collection, bot_message_obj)
    
    recent_history_for_extraction = history[:5]
    extract_and_save_user_context_data(user, user_message_text, bot_message_text, recent_history_for_extraction, api_key)

    # ë””ë²„ê¹…ì„ ìœ„í•´ ìµœì¢… explanation ë‚´ìš©ì„ í„°ë¯¸ë„ì— ì¶œë ¥
    print("\n" + "-"*20 + " [Debug] Response Explanation " + "-"*20)
    print(explanation)
    print("-"*66 + "\n")

    return bot_message_text, explanation, bot_message_obj, user_message_obj


# ----------------------------------------------------
# ë¹„ë™ê¸° GPT ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ í•¨ìˆ˜ (Async ë²„ì „)
# ----------------------------------------------------

async def async_stream_openai_api(model_to_use: str, messages: list):
    """
    AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ GPT APIë¥¼ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.
    (ê¸°ì¡´ _call_openai_apiì™€ ìœ ì‚¬í•˜ì§€ë§Œ async í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)
    """
    # ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        client = AsyncOpenAI() # í™˜ê²½ ë³€ìˆ˜ì—ì„œ í‚¤ ìë™ ë¡œë“œ
    except Exception as e:
        print(f"AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        raise APIError(f"AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ íŒŒë¼ë¯¸í„°
    params = {
        "model": model_to_use,
        "messages": messages,
        "temperature": 0.7,
        "top_p": 0.9,
        "frequency_penalty": 0.2,
        "presence_penalty": 0.1,
        "stream": True # ğŸ‘ˆ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ê°•ì œ
    }

    try:
        # ë¹„ë™ê¸° í˜¸ì¶œ
        response_stream = await client.chat.completions.create(**params)
        return response_stream # AsyncGenerator ê°ì²´ ë°˜í™˜
        
    except APIError:
        # APIErrorëŠ” ë‹¤ì‹œ ë°œìƒì‹œì¼œ consumers.pyì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•©ë‹ˆë‹¤.
        raise
